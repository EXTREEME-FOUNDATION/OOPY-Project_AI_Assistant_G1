{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd15f883796ced19",
   "metadata": {},
   "source": [
    "# AI Assistant\n",
    "## Group Members:\n",
    " - Krylova Alena\n",
    " - Dudic Mateja\n",
    " - Saavedra Triana Erwin Omar\n",
    " - Maringer Kelvin\n",
    "\n",
    "## Python Version:\n",
    " - 3.13\n",
    "\n",
    "## Contributions:\n",
    " - Krylova Alena:\n",
    "     - ...\n",
    " - Dudic Mateja:\n",
    "     - ...\n",
    " - Saavedra Triana Erwin Omar:\n",
    "     - ...\n",
    " - Maringer Kelvin:\n",
    "     - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16272c01b8c7987e",
   "metadata": {},
   "source": [
    "# FIRST TIME SETUP\n",
    "# ----------------\n",
    "# MAKE SURE THAT THIS CELL RUNS WITHOUT ERRORS BEFORE PROCEEDING\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e896f8188369ee68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:31:21.140521954Z",
     "start_time": "2026-01-16T14:31:20.243176822Z"
    }
   },
   "outputs": [],
   "source": [
    "# All the packages that have to be installed should be listed here\n",
    "%pip install numpy pandas matplotlib seaborn kagglehub ipywidgets --quiet\n",
    "# This will filter out the output from Jupyter Notebooks when committing to git, so that diffs are cleaner\n",
    "! git config filter.strip-notebook-output.clean 'jupyter nbconvert --ClearOutputPreprocessor.enabled=True --to=notebook --stdin --stdout --log-level=ERROR'\n",
    "\n",
    "import kagglehub\n",
    "import platform\n",
    "\n",
    "# Download latest version\n",
    "dataset_path = kagglehub.dataset_download(\"prince7489/daily-ai-assistant-usage-behavior-dataset\") + (\"/Daily_AI_Assistant_Usage_Behavior_Dataset.csv\" if platform.system() != \"Windows\" else \"\\\\Daily_AI_Assistant_Usage_Behavior_Dataset.csv\")\n",
    "\n",
    "print(\"Path to dataset files:\", dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74fab031dec6594",
   "metadata": {},
   "source": [
    "# ----------------------\n",
    "# ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9776dc96f35539c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:31:21.185249631Z",
     "start_time": "2026-01-16T14:31:21.168229795Z"
    }
   },
   "outputs": [],
   "source": [
    "#All the imports should be listed here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sea\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28858041b25066",
   "metadata": {},
   "source": [
    "## *Dataset Overview*\n",
    "The Daily AI Assistant Usage Behavior Dataset captures real-world patterns of how users interact with AI assistants throughout their daily activities. It provides insights into when, how, and for what purposes people used AI tools, as well as session characteristics and user satisfaction.\n",
    "\n",
    "The dataset is published on the Kaggle platform and is intended for researchers, developers, and data science practitioners interested in user behavior analysis, personalization systems, recommendation engines, and conversational AI. It covers a wide range of AI usage scenarios, including learning, productivity, research, and routine daily tasks.\n",
    "\n",
    "The dataset contains 300 rows and 8 columns.\n",
    "\n",
    "*Features (their meaning and data types):*  \n",
    "1st column: timestamp - date and time when the interaction with an AI tool started, data type - categorical (string)  \n",
    "2nd column: device - type of device which was used to access an AI tool (desktop, mobile, smart speaker), data type - categorical (string)  \n",
    "3rd column: usage_category - for what purpose the user used an AI tool (education, daily tasks, research and etc), data type - categorical (string)  \n",
    "4th column: prompt_length - lenght of the user`s prompt (measured in charakters), data type - integer  \n",
    "5th column: session_length_minutes - duration of the session in minutes, data type - float  \n",
    "6th column: satisfaction_rating - user satisfaction score from 1 to 5, data type - integer  \n",
    "7th column: assistant_model - which AI assistant model was used during the session, data type - categorical(string)  \n",
    "8th column: tokens_used - number of tokens used during the session, data type - integer  \n",
    "\n",
    "Most features from the data set are categorical, making the dataset suitable for analyzing patterns and user behavior segmentation (for example, feature 'timestamp' allows to see if people use AI tools more often on weeekdays or weekends, in the mornings or in the evenings).\n",
    "\n",
    "To obtain a statistical summary of the numerical features, the describe() method was used.\n",
    "It provided key statistics such as mean, standard deviation, minimum and maximum values, as well as quartiles. It allows to better understand distributaion of data.   \n",
    "*Some observations from the desccribe() function:*   \n",
    "The average prompt length is 129 characters, it indicates that users often submit detailed prompts.  \n",
    "The average session duration is about 7.7 minutes, indicating that most interactions with the AI assistant are relatively short.  \n",
    "The average satisfaction rating is close to 3 (on a scale from 1 to 5), which shows users` experience in general is neutral (or positiv.)  \n",
    "Token usage varies significantly, showing the differences in query complexity.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202670a5bdcc0674",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:31:21.212695722Z",
     "start_time": "2026-01-16T14:31:21.186286238Z"
    }
   },
   "outputs": [],
   "source": [
    "## Code for the dataset overview Here\n",
    "data = pd.read_csv(dataset_path)\n",
    "print(data.head())\n",
    "print(data.info())   # to get information about the dataframe (number of rows, columns, data types)\n",
    "# to get basic statistics about the dataframe (mean, std, min, max, etc.)\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f27a1210a09e32",
   "metadata": {},
   "source": [
    "## *Data Quality Check*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2b86ae29dce109",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:31:21.375363043Z",
     "start_time": "2026-01-16T14:31:21.214511520Z"
    }
   },
   "outputs": [],
   "source": [
    "## Code for the data quality check Here\n",
    "print(f\"Missing values per columns: \\n {data.isnull().sum()}\") \n",
    "# The dataset contains no missing values\n",
    "rows = 1\n",
    "cols = len(data.select_dtypes(include=[np.number]).columns)\n",
    "fig, axes = plot.subplots(rows, cols, figsize=(15,5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(data.select_dtypes(include=[np.number]).columns):\n",
    "    sea.boxplot(y=data[col], ax=axes[i])\n",
    "plot.suptitle(\"Boxplot for the numerical columns \")\n",
    "plot.show()\n",
    "\n",
    "#from the boxplots we can see that there are no outliers in the numerical columns\n",
    "\n",
    "print(data['device'].value_counts())\n",
    "print(data['usage_category'].value_counts())\n",
    "print(data['assistant_model'].value_counts())\n",
    "# For the categorical columns, we examined  the unique values and their frequencies. There are no unusual or extremely rare entries, so no outliers were detected in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41627c5b859e5e66",
   "metadata": {},
   "source": [
    "## *Data-Preprocessing*\n",
    " - Additional Notes etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29179a8821b1a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:31:21.428648032Z",
     "start_time": "2026-01-16T14:31:21.376846808Z"
    }
   },
   "outputs": [],
   "source": [
    "# From here you can take for the Data Quality Check\n",
    "RAW_data = pd.read_csv(dataset_path)\n",
    "\n",
    "# first we check the number of missing values in each column\n",
    "print(RAW_data.isnull().sum())\n",
    "# after checking we can see that there are no missing values in the dataset\n",
    "\n",
    "# so for the outliers in this dataset , I think the best aproach would be to leave them and just mark them as outliers. In this dataset the outliers might be relevant data from users that have a diferent behavior than the average user, so removing them would mean losing relevant data.\n",
    "\n",
    "# now we will check for outliers using the IQR method\n",
    "\n",
    "y = RAW_data.select_dtypes(include=[np.number])\n",
    "print(y)\n",
    "for column in y:\n",
    "    quartile_min = RAW_data[column].quantile(0.25)\n",
    "    quartile_max = RAW_data[column].quantile(0.75)\n",
    "\n",
    "    IQR = quartile_max - quartile_min\n",
    "\n",
    "    lower_bound = quartile_min - 1.5 * IQR\n",
    "    upper_bound = quartile_max + 1.5 * IQR\n",
    "\n",
    "    outliers_promt_length = RAW_data[(RAW_data[column] < lower_bound) | (RAW_data[column] > upper_bound)].count()\n",
    "    outliers_promt_length = outliers_promt_length.sum()\n",
    "\n",
    "    print(f\"the number of outliers in {column} is the following: \\n{outliers_promt_length}\")\n",
    "\n",
    " # Start of the data preprocessing\n",
    "\n",
    "# after checking we can see that there are no outliers in the dataset, surprinsing but good.\n",
    "# next we will check for duplicates in the dataset\n",
    "x = RAW_data.duplicated().sum()\n",
    "print(f\"the number of duplicates in the dataset is the following: \\n{x}\")\n",
    "# after checking we can see that there are no duplicates in the dataset\n",
    "\n",
    "#\n",
    "\n",
    "# so we continue with creating the required columns\n",
    "\n",
    "\n",
    "# I made an funtion for this part so its easier to read , and taking noticing that the timestamp is an string i decided to slice the string to get the hour part and then convert it to int to compare it\n",
    "def timeOfDay(hour):\n",
    "    if 5 <= hour <= 11:\n",
    "        return \"morning\"\n",
    "    elif 12 <= hour <= 17:\n",
    "        return \"afternoon\"\n",
    "    elif 18 <= hour <= 22:\n",
    "        return \"evening\"\n",
    "    else:\n",
    "        return \"Night\"\n",
    "\n",
    "RAW_data[\"timeOfDay\"] = RAW_data[\"timestamp\"].apply(lambda x:timeOfDay(int(x[11:-6])))\n",
    "RAW_data[\"year\"] = RAW_data[\"timestamp\"].apply(lambda x:int(x[0:4]))\n",
    "\n",
    "# now we are going to convert the columns and timestamp to their proper datatypes\n",
    "\n",
    "RAW_data[\"timestamp\"] = pd.to_datetime(RAW_data[\"timestamp\"])\n",
    "RAW_data[\"device\"] = RAW_data[\"device\"].astype(\"category\")\n",
    "RAW_data[\"assistant_model\"] = RAW_data[\"assistant_model\"].astype(\"category\")\n",
    "RAW_data[\"timeOfDay\"] = RAW_data[\"timeOfDay\"].astype(\"category\")\n",
    "RAW_data[\"usage_category\"] = RAW_data[\"usage_category\"].astype(\"category\")\n",
    "\n",
    "# note that the numericals stay the same, and I decided to leave year as a number\n",
    "\n",
    "RAW_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fa4e3e17c9bb6d",
   "metadata": {},
   "source": [
    "## *Data Analysis*\n",
    " - Additional Notes etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15f1454448cd1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:31:21.711356543Z",
     "start_time": "2026-01-16T14:31:21.452721082Z"
    }
   },
   "outputs": [],
   "source": [
    "#1. Different AI Assistants used (count and percentage).\n",
    "\n",
    "assistant = RAW_data['assistant_model'] #selecting the column assistant_model\n",
    "count = assistant.value_counts() #counting how many times each assistant appears\n",
    "percentage = ((count/RAW_data['assistant_model'].count())*100).round(2) #calculating the percentage of each assistants occurrence\n",
    "\n",
    "different_assistants = pd.DataFrame({'count': count, 'percentage': percentage}) #making a dataframe with the results\n",
    "print(different_assistants)\n",
    "#There is 5 different AI models in the dataset\n",
    "\n",
    "#2. Average session length per assistant model\n",
    "\n",
    "average_session_length = RAW_data.groupby('assistant_model')['session_length_minutes'].mean().round(2)\n",
    "average_session_length_output = pd.DataFrame({'Average length': average_session_length})\n",
    "print(average_session_length_output)\n",
    "#Average session length is relatively similar for all AI models, with the highest being GPT-5 at 8.15 and the lowest being o1 at 7.18 minutes\n",
    "\n",
    "#3. Usage category per assistant model\n",
    "pivotinho = pd.pivot_table(RAW_data, index='assistant_model', columns='usage_category', aggfunc='count', values='timestamp')\n",
    "print(pivotinho)\n",
    "# An interesting observation is that o1 is used the most for Writing and Education compared to other categories, most likely due to better reasoning than other models, \n",
    "# In general the most used models are the three GPT models, with GPT-4 being the most consistently used of the three\n",
    "\n",
    "#4. Longest average prompt length and use time per task\n",
    "longest_avg_prompt = RAW_data.groupby('usage_category')['prompt_length'].mean().round(2)\n",
    "print(longest_avg_prompt)\n",
    "\n",
    "longest_avg_time = RAW_data.groupby('usage_category')['session_length_minutes'].mean().round(2)\n",
    "print(longest_avg_time)\n",
    "#The longest average prompt length is in Research with 141.26 characters on average, while the longest average session length is for coding with 8.51 seconds\n",
    "\n",
    "#5. Usage category per time of day\n",
    "usage_category_per_timeOfDay = pd.pivot_table(RAW_data, index='usage_category', columns='timeOfDay', aggfunc='count', values='timestamp')\n",
    "print(usage_category_per_timeOfDay)\n",
    "# Most categories have a specific time of day during which they are the least occurent. For example, education is least used at night, while writing is the least used during the evening\n",
    "\n",
    "\n",
    "#6. Popularity of assistants over time\n",
    "assistant_model_per_year = pd.pivot_table(RAW_data, index='assistant_model', columns='year', aggfunc='count', values='timestamp')\n",
    "print(assistant_model_per_year)\n",
    "#just one year is given and the most used assistant is GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9288eee8972a0a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:31:26.625062762Z",
     "start_time": "2026-01-16T14:31:26.494139556Z"
    }
   },
   "outputs": [],
   "source": [
    "## code for data analysis here\n",
    "\n",
    "#Visualizations:\n",
    "#– Plot distributions of key features using histograms, KDE plots, and boxplots.\n",
    "#– Use color to distinguish individual assistants.\n",
    "\n",
    "def rem_uscore(axis):\n",
    "    \"\"\"Removes underscores from x and y axis labels because it looks better\"\"\"\n",
    "    axis.set_xlabel(axis.get_xlabel().replace(\"_\", \" \").replace(\"minutes\", \"in min.\"))\n",
    "    axis.set_ylabel(axis.get_ylabel().replace(\"_\", \" \").replace(\"minutes\", \"in min.\"))\n",
    "    print(axis.get_xlabel())\n",
    "\n",
    "#\n",
    "# HISTOGRAMS\n",
    "#\n",
    "\n",
    "fg, axes = plot.subplots(1, 3, figsize=(30, 10))\n",
    "fg.suptitle(\"Histograms (∑300 entries)\")\n",
    "\n",
    "#  sea.kdeplot(data=RAW_data, x=\"satisfaction_rating\", hue=\"assistant_model\", fill=True,alpha=.1,palette=\"muted\")\n",
    "#  plot.gca().axes.get_yaxis().set_visible(False) # Hide \"Density\" label since it's annoying\n",
    "\n",
    "\n",
    "# Histograms are chosen to show the distribution amongst assistant models and devices.\n",
    "# This helps to visualize which moedels and devices are actually being used. (NOTE: this sample size is quite small (300 entries) so the data might not be real world applicable)\n",
    "# I cannot imagine that smart speakers are the most used platform for AI assistants, but hey, who knows! maybe i just havn't kept in touch with the latest trends :')\n",
    "# NOTE: who TF uses a smart speaker???\n",
    "\n",
    "sea.histplot(ax=axes[0],data=RAW_data, x=\"assistant_model\",stat=\"count\", palette=\"muted\", hue=\"assistant_model\",legend=False)\n",
    "axes[0].set_title(\"Assistant Model count\")\n",
    "rem_uscore(axes[0])\n",
    "print(\"Most people seem to use GPT-4o, which is interesting as it is not exactly the cheapest model available.\")\n",
    "\n",
    "\n",
    "\n",
    "#  axes[1].tick_params(left=False)  # Remove y-axis ticks\n",
    "\n",
    "print(\"The biggest platform is relatively suprising: smart speakers. I assume that this means devices like Amazon Alexa and Google Home, which is interesting since these devices are not really known for their AI capabilities. Wired... and interesting!\")\n",
    "\n",
    "\n",
    "sea.histplot(ax=axes[1],data=RAW_data, x=\"usage_category\", palette=\"muted\", hue=\"usage_category\",legend=False)\n",
    "\n",
    "\n",
    "#sea.histplot(ax=axes[2],data=RAW_data, x=\"usage_category\",palette=\"muted\", hue=\"device\",multiple=\"stack\")\n",
    "\n",
    "\n",
    "#sea.histplot(ax=axes[2],data=RAW_data, x=\"device\",palette=\"muted\",alpha=.5, hue=\"usage_category\",multiple=\"stack\")\n",
    "\n",
    "axes[1].set_title(\"Usage Category count\")\n",
    "axes[1].set_ylabel('')  # Remove y-axis label\n",
    "axes[1].tick_params(axis='x', labelrotation=45) # super Fancy 45° rotation for extra coolness\n",
    "rem_uscore(axes[1])\n",
    "\n",
    "\n",
    "\n",
    "sea.histplot(ax=axes[2],data=RAW_data, x=\"device\", palette=\"muted\", hue=\"device\",legend=False,alpha=.25)\n",
    "axes[2].set_title(\"Device count\")\n",
    "\n",
    "#  axes[2].set(yticklabels=[])\n",
    "axes[2].set_ylabel('')  # Remove y-axis label\n",
    "rem_uscore(axes[2])\n",
    "\n",
    "axes_2_overlay = axes[2].twinx()# This combines two plots into one (so both the use counts of devices and the breakdown into usage categories can be seen AT THE SAME TIME.)\n",
    "\n",
    "sea.countplot(ax=axes_2_overlay, data=RAW_data, x=\"device\", hue=\"usage_category\", palette=\"muted\") # This is so cool. I love it.\n",
    "axes_2_overlay.set_ylabel('Usage Count')  # Remove y-axis label\n",
    "axes_2_overlay.get_xticklabels()[0].set_color(sea.color_palette(\"muted\")[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"The most common usage for AI seems to be education. Depending on the definition of this category, this could mean that a lot of people are using these assistats for homework and study-help.\")\n",
    "print(\"This honestly makes me question where this data is from, since I would expect a LOT more people to use AI in a more professional setting (work, coding, writing etc.) rather than for education.\")\n",
    "print(\"Coding one of the least common, which is very suprising to me, considering that AI coding assistants are one of the more ACTUALY USEFUL applications of AI right now. Interesting!\")\n",
    "\n",
    "#desktop_writing\n",
    "#print(RAW_data[(RAW_data[\"device\"]==\"Smart Speaker\") & (RAW_data[\"usage_category\"]==\"Coding\")].value_counts())#?????????????? -> Why would someone use a smart speaker for coding??? -- This dataset is definetly not real. (Alexa, commit & push the code.)\n",
    "\n",
    "\n",
    "plot.show()\n",
    "\n",
    "\n",
    "#\n",
    "# KDE PLOTS\n",
    "#\n",
    "kdeplots_defcon={\"alpha\":.25,\"fill\":True,\"palette\":\"muted\",\"common_norm\":False} # Default parameters for all KDE plots via **UNPACKING MY BELOVED\n",
    "\n",
    "def cts_kdeplot(ax, data, x, hue,title=None) -> None: # Helper function for creating KDE plots\n",
    "    sea.kdeplot(ax=ax,data=data, x=x, hue=hue, **kdeplots_defcon) # Makes the KDE plot\n",
    "    ax.set_xlim(data[x].min(),data[x].max()) # Set x-axis limits (removes tapering of the KDE at the edges)\n",
    "    ax.set_title(f\"{x} by {hue} type\" if title is None else title) # Title formatting\n",
    "    sea.move_legend(ax, \"lower left\") # self-explanatory\n",
    "    ax.set(yticklabels=[]) # Remove y-axis numbers\n",
    "    ax.set_ylabel('')  # Remove y-axis label\n",
    "    ax.tick_params(left=False)  # Remove y-axis ticks\n",
    "    rem_uscore(ax)\n",
    "    \n",
    "    \n",
    "# KDE plots are chosen to show the distribution of \n",
    "#\n",
    "#\n",
    "    \n",
    "    \n",
    "fg, axes = plot.subplots(1, 3, figsize=(30, 10))\n",
    "fg.suptitle(\"KDE Plots YEAHHH\")\n",
    "\n",
    "cts_kdeplot(axes[0],RAW_data,\"session_length_minutes\",\"device\",\"session length by device type\")\n",
    "\n",
    "print(\"This is actually quite interesting! The session length seems to be shorter on desktop devices compared to mobile devices, which is wired. (one would think that desktop users would spend more time because of work/study etc.)\")\n",
    "print(\"Similarly, tablets have the longest session lengths on average. This divide between mobile and desktop could stem from the different use cases for each device type. (or the time it takes to type / enter prompts)\")\n",
    "print(\"This points towards desktop users using the AI assistant for quick queries, while mobile/tablet users might be engaging in longer interactions. Strange!\")\n",
    "\n",
    "cts_kdeplot(axes[1],RAW_data,\"prompt_length\",\"device\",\"prompt length by device type\")\n",
    "\n",
    "print(\"Looking at the prompt lengths, we can see that desktop users tend to have longer prompts on average compared to mobile and tablet users.\")\n",
    "print(\"This could be due to the ease of typing on a physical keyboard, allowing for longer and more complex prompts. This is pretty strange though, since the session lengths were shorter on desktop.\")\n",
    "\n",
    "cts_kdeplot(axes[2],RAW_data,\"tokens_used\",\"assistant_model\",\"tokens used by model type\")\n",
    "\n",
    "print(\"As expected, the more advanced models like GPT-5 and GPT-4o tend to use more tokens on average compared to older models like o1.\")\n",
    "print(\"However, mini seems to use the most tokens on average, which could either stem from its use (longer prompts on average) or its complexity. (which is weired since mini is supposed to be a smaller model). Strange again!\")\n",
    "\n",
    "plot.show()\n",
    "\n",
    "\n",
    "#\n",
    "# BOXPLOTS LEZGO\n",
    "#\n",
    "\n",
    "fg, axes = plot.subplots(1, 2, figsize=(30, 10))\n",
    "fg.suptitle(\"Box Plots\")\n",
    "\n",
    "\n",
    "#sea.boxplot(ax=axes[0],data=RAW_data, x=\"assistant_model\",hue=\"assistant_model\", y=\"satisfaction_rating\", palette=\"muted\",medianprops={\"color\": \"r\", \"linewidth\": 2},notch=True)\n",
    "\n",
    "sea.boxplot(ax=axes[0],data=RAW_data, x=\"assistant_model\",hue=\"assistant_model\", y=\"tokens_used\", palette=\"muted\",medianprops={\"color\": \"r\", \"linewidth\": 2},notch=True)\n",
    "axes[0].set_title(\"Tokens Used by Assistant Model\")\n",
    "rem_uscore(axes[0])\n",
    "\n",
    "print(\"assistant model vs tokens used is actually quite interesting (genuenly!). One can see that the \\\"advancedness\\\" of the model doesn't really correlate with the number of tokens used. This could either point towards good optimization of the newer models, or simply that users are using the models in different ways.\")\n",
    "print(\"Mini seems to have the highest median token, whilst having a relatively big spread. The token size seems to vary quite a lot.\")\n",
    "\n",
    "print(\"device to session length is also notable, in that the session length seems to be quite stable across the different device types. The spread is also quite small (ranging from ~11 to ~5 minutes on most devices)\")\n",
    "\n",
    "\n",
    "#print(\"Interestingly enough, most models seem to have an completely identical satisfaction rating distribution. This is quite suprising and implies that this data might be synthetic. (i calculated it myself and all models have a mean of exactly 3 with max of .2 difference). Seems like there should be a bigger difference between models, especially considering that each model should (at least in theory) improved over the last.\")\n",
    "#print(\"GPT-5 seems to have the lowest satisfaction, however, the 5.1 version has the highest satisfaction. This could point towards some issues with GPT-5 that were fixed in 5.1. IG\")\n",
    "\n",
    "# <ignore_this>\n",
    "print(RAW_data[[\"assistant_model\",\"satisfaction_rating\"]].groupby(\"assistant_model\").mean())\n",
    "print(RAW_data[[\"assistant_model\",\"satisfaction_rating\"]].groupby(\"assistant_model\").quantile(.75))\n",
    "print(RAW_data[[\"assistant_model\",\"satisfaction_rating\"]].groupby(\"assistant_model\").quantile(.25))\n",
    "# </ignore_this>\n",
    "\n",
    "\n",
    "sea.boxplot(ax=axes[1],data=RAW_data, x=\"device\",hue=\"device\", y=\"session_length_minutes\", palette=\"muted\",medianprops={\"color\": \"r\", \"linewidth\": 2},notch=True)\n",
    "axes[1].set_title(\"Session Length by Device Type\")\n",
    "rem_uscore(axes[1])\n",
    "plot.show()\n",
    "\n",
    "\n",
    "#  sea.boxplot(data=RAW_data, x=\"assistant_model\",hue=\"assistant_model\", y=\"session_length_minutes\", palette=\"muted\")\n",
    "#  plot.title(\"Boxplot of Session Length by Assistant Model\")\n",
    "#  plot.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3891197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any features that clearly differentiate device types?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
